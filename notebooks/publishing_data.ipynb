{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publishing data with OME Zarr\n",
    "\n",
    "Driven by the need to quickly publish a recent COVID dataset in the IDR, the OME team has accelerated development of an archival version of bioimaging data in a cloud-enabled format for easier download and re-analysis. A number of images from the Image Data Resource (IDR) have been converted using the bioformats2raw tool into the Zarr format and then transferred to EBIâ€™s S3 servers for public download. By working from a common representation, these files can be scalably accessed over common web protocols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"zarr-diagram.png\" style=\"height:300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bioformats2raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BFVERSION=\"0.2.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$BFVERSION\"\n",
    "BFREPO=https://github.com/glencoesoftware/bioformats2raw/releases/download\n",
    "BF2RAW=bioformats2raw-${1}\n",
    "test -e ${BF2RAW}.zip || wget ${BFREPO}/v${BF2RAW}/${BF2RAW}.zip\n",
    "test -e ${BF2RAW} || unzip ${BF2RAW}.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing required parameters: <inputPath>, <outputPath>\n",
      "Usage: \u001b[1m<main class>\u001b[21m\u001b[0m [\u001b[33m--debug\u001b[39m\u001b[0m] [\u001b[33m--extra-readers\u001b[39m\u001b[0m[=\u001b[3m<extraReaders>\u001b[23m\u001b[0m[,\n",
      "                    \u001b[3m<extraReaders>\u001b[23m\u001b[0m...]]]...\n",
      "                    [\u001b[33m--additional-scale-format-string-args\u001b[39m\u001b[0m=\u001b[3m<additionalScaleForma\u001b[23m\u001b[0m\n",
      "\u001b[3m                    tStringArgsCsv>\u001b[23m\u001b[0m] [\u001b[33m-c\u001b[39m\u001b[0m=\u001b[3m<compressionType>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--compression-parameter\u001b[39m\u001b[0m=\u001b[3m<compressionParameter>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--dimension-order\u001b[39m\u001b[0m=\u001b[3m<dimensionOrder>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--file_type\u001b[39m\u001b[0m=\u001b[3m<fileType>\u001b[23m\u001b[0m] [\u001b[33m-h\u001b[39m\u001b[0m=\u001b[3m<tileHeight>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--max_cached_tiles\u001b[39m\u001b[0m=\u001b[3m<maxCachedTiles>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--max_workers\u001b[39m\u001b[0m=\u001b[3m<maxWorkers>\u001b[23m\u001b[0m] [\u001b[33m--pyramid-name\u001b[39m\u001b[0m=\u001b[3m<pyramidName>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m-r\u001b[39m\u001b[0m=\u001b[3m<pyramidResolutions>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m--scale-format-string\u001b[39m\u001b[0m=\u001b[3m<scaleFormatString>\u001b[23m\u001b[0m]\n",
      "                    [\u001b[33m-w\u001b[39m\u001b[0m=\u001b[3m<tileWidth>\u001b[23m\u001b[0m] \u001b[33m<inputPath>\u001b[39m\u001b[0m \u001b[33m<outputPath>\u001b[39m\u001b[0m\n",
      "\u001b[33m \u001b[39m\u001b[0m     \u001b[33m<inputPath>\u001b[39m\u001b[0m    file to convert\n",
      "\u001b[33m \u001b[39m\u001b[0m     \u001b[33m<outputPath>\u001b[39m\u001b[0m   path to the output pyramid directory\n",
      "      \u001b[33m--additional-s\u001b[39m\u001b[0m\u001b[33mcale-format-string-args\u001b[39m\u001b[0m=\u001b[3m<additionalScaleFormatStringArgsCsv>\u001b[23m\u001b[0m\n",
      "                     Additional format string argument CSV file (without header\n",
      "                       row).  Arguments will be added to the end of the scale\n",
      "                       format string mapping the at the corresponding CSV row\n",
      "                       index.  It is expected that the CSV file contain exactly\n",
      "                       the same number of rows as the input file has series\n",
      "  \u001b[33m-c\u001b[39m\u001b[0m, \u001b[33m--compression\u001b[39m\u001b[0m=\u001b[3m<compressionType>\u001b[23m\u001b[0m\n",
      "                     Compression type for n5 (blosc, bzip2, gzip, lz4, raw, xz;\n",
      "                       default: blosc)\n",
      "      \u001b[33m--compression-\u001b[39m\u001b[0m\u001b[33mparameter\u001b[39m\u001b[0m=\u001b[3m<compressionParameter>\u001b[23m\u001b[0m\n",
      "                     Integer parameter for chosen compression (see https:\n",
      "                       //github.com/saalfeldlab/n5/blob/master/README.md )\n",
      "      \u001b[33m--debug\u001b[39m\u001b[0m        Turn on debug logging\n",
      "      \u001b[33m--dimension-or\u001b[39m\u001b[0m\u001b[33mder\u001b[39m\u001b[0m=\u001b[3m<dimensionOrder>\u001b[23m\u001b[0m\n",
      "                     Override the input file dimension order in the output file\n",
      "                       [Can break compatibility with raw2ometiff] (XYZCT,\n",
      "                       XYZTC, XYCTZ, XYCZT, XYTCZ, XYTZC)\n",
      "      \u001b[33m--extra-reader\u001b[39m\u001b[0m\u001b[33ms\u001b[39m\u001b[0m[=\u001b[3m<extraReaders>\u001b[23m\u001b[0m[,\u001b[3m<extraReaders>\u001b[23m\u001b[0m...]]\n",
      "                     Separate set of readers to include; (default: [class com.\n",
      "                       glencoesoftware.bioformats2raw.PyramidTiffReader, class\n",
      "                       com.glencoesoftware.bioformats2raw.MiraxReader])\n",
      "      \u001b[33m--file_type\u001b[39m\u001b[0m=\u001b[3m<f\u001b[23m\u001b[0m\u001b[3mileType>\u001b[23m\u001b[0m\n",
      "                     Tile file extension: n5, zarr (default: n5) [Can break\n",
      "                       compatibility with raw2ometiff]\n",
      "  \u001b[33m-h\u001b[39m\u001b[0m, \u001b[33m--tile_height\u001b[39m\u001b[0m=\u001b[3m<tileHeight>\u001b[23m\u001b[0m\n",
      "                     Maximum tile height to read (default: 1024)\n",
      "      \u001b[33m--max_cached_t\u001b[39m\u001b[0m\u001b[33miles\u001b[39m\u001b[0m=\u001b[3m<maxCachedTiles>\u001b[23m\u001b[0m\n",
      "                     Maximum number of tiles that will be cached across all\n",
      "                       workers (default: 64)\n",
      "      \u001b[33m--max_workers\u001b[39m\u001b[0m=\u001b[3m<maxWorkers>\u001b[23m\u001b[0m\n",
      "                     Maximum number of workers (default: 16)\n",
      "      \u001b[33m--pyramid-name\u001b[39m\u001b[0m=\u001b[3m<pyramidName>\u001b[23m\u001b[0m\n",
      "                     Name of pyramid (default: data.n5) [Can break\n",
      "                       compatibility with raw2ometiff]\n",
      "  \u001b[33m-r\u001b[39m\u001b[0m, \u001b[33m--resolutions\u001b[39m\u001b[0m=\u001b[3m<pyramidResolutions>\u001b[23m\u001b[0m\n",
      "                     Number of pyramid resolutions to generate\n",
      "      \u001b[33m--scale-format\u001b[39m\u001b[0m\u001b[33m-string\u001b[39m\u001b[0m=\u001b[3m<scaleFormatString>\u001b[23m\u001b[0m\n",
      "                     Format string for scale paths; the first two arguments\n",
      "                       will always be series and resolution followed by any\n",
      "                       additional arguments brought in from\n",
      "                       `--additional-scale-format-string-args` [Can break\n",
      "                       compatibility with raw2ometiff] (default: %d/%d)\n",
      "  \u001b[33m-w\u001b[39m\u001b[0m, \u001b[33m--tile_width\u001b[39m\u001b[0m=\u001b[3m<\u001b[23m\u001b[0m\u001b[3mtileWidth>\u001b[23m\u001b[0m\n",
      "                     Maximum tile width to read (default: 1024)\n"
     ]
    }
   ],
   "source": [
    "!bioformats2raw-{BFVERSION}/bin/bioformats2raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-19 23:14:45,352 [main] INFO  c.g.bioformats2raw.Converter - Output will be incompatible with raw2ometiff (pyramidName: data.zarr, scaleFormatString: %d/%d)\n",
      "2020-05-19 23:14:45,692 [main] INFO  loci.formats.ImageReader - FakeReader initializing a.fake\n",
      "2020-05-19 23:14:45,830 [main] INFO  c.g.bioformats2raw.Converter - Using 2 pyramid resolutions\n",
      "2020-05-19 23:14:45,830 [main] INFO  c.g.bioformats2raw.Converter - Preparing to write pyramid sizeX 512 (tileWidth: 1024) sizeY 512 (tileWidth: 1024) imageCount 1\n",
      "2020-05-19 23:14:46,080 [main] WARN  c.g.bioformats2raw.Converter - Reducing active tileWidth to 512\n",
      "2020-05-19 23:14:46,081 [main] WARN  c.g.bioformats2raw.Converter - Reducing active tileHeight to 512\n",
      "2020-05-19 23:14:46,094 [pool-1-thread-1] INFO  c.g.bioformats2raw.Converter - requesting tile to write at [0, 0, 0, 0, 0] to /0/0\n",
      "2020-05-19 23:14:46,104 [pool-1-thread-1] INFO  c.g.bioformats2raw.Converter - tile read complete 1/1\n",
      "2020-05-19 23:14:46,104 [pool-1-thread-1] INFO  org.perf4j.TimingLogger - start[1589922886094] time[10] tag[getTile]\n",
      "2020-05-19 23:14:46,106 [pool-1-thread-1] INFO  c.g.bioformats2raw.Converter - successfully wrote at [0, 0, 0, 0, 0] to /0/0\n",
      "2020-05-19 23:14:46,106 [pool-1-thread-1] INFO  c.g.bioformats2raw.Converter - Successfully processed tile; resolution=0 plane=0 xx=0 yy=0 width=512 height=512\n",
      "2020-05-19 23:14:46,106 [main] WARN  c.g.bioformats2raw.Converter - Reducing active tileWidth to 256\n",
      "2020-05-19 23:14:46,106 [main] WARN  c.g.bioformats2raw.Converter - Reducing active tileHeight to 256\n",
      "2020-05-19 23:14:46,109 [pool-1-thread-2] INFO  c.g.bioformats2raw.Converter - requesting tile to write at [0, 0, 0, 0, 0] to /0/1\n",
      "2020-05-19 23:14:46,112 [pool-1-thread-2] INFO  org.perf4j.TimingLogger - start[1589922886110] time[2] tag[getTileDownsampled]\n",
      "2020-05-19 23:14:46,112 [pool-1-thread-2] INFO  c.g.bioformats2raw.Converter - tile read complete 1/1\n",
      "2020-05-19 23:14:46,112 [pool-1-thread-2] INFO  org.perf4j.TimingLogger - start[1589922886109] time[2] tag[getTile]\n",
      "Exception in thread \"pool-1-thread-2\" java.lang.NoSuchMethodError: java.nio.ByteBuffer.position(I)Ljava/nio/ByteBuffer;\n",
      "\tat com.glencoesoftware.bioformats2raw.Converter.getTileDownsampled(Converter.java:604)\n",
      "\tat com.glencoesoftware.bioformats2raw.Converter.getTile(Converter.java:633)\n",
      "\tat com.glencoesoftware.bioformats2raw.Converter.processTile(Converter.java:721)\n",
      "\tat com.glencoesoftware.bioformats2raw.Converter.lambda$saveResolutions$2(Converter.java:913)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "!bioformats2raw-{BFVERSION}/bin/bioformats2raw --file_type=zarr --dimension-order=XYZCT a.fake /tmp/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk 11.0.7 2020-04-14\r\n",
      "OpenJDK Runtime Environment (build 11.0.7+10)\r\n",
      "OpenJDK 64-Bit Server VM (build 11.0.7+10, mixed mode)\r\n"
     ]
    }
   ],
   "source": [
    "!java --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### omero-ms-zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSVERSION=\"0.1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$MSVERSION\"\n",
    "MSREPO=https://github.com/ome/omero-ms-zarr/archive\n",
    "MSZARR=v${1}\n",
    "test -e ${MSZARR}.zip || wget ${MSREPO}/${MSZARR}.zip\n",
    "test -e omero-ms-zarr-${1} || unzip ${MSZARR}.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%script --bg bash\n",
    "cd omero-ms-zarr-0.1.1\n",
    "cat <<EOF > cfg\n",
    "omero.data.dir=/tmp/ome1\n",
    "omero.db.name=ome1\n",
    "omero.db.user=postgres\n",
    "omero.ms.zarr.net.path.image=/idr/zarr/v0.1/{image}.zarr/\n",
    "EOF\n",
    "gradle run --args=cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.get(\"http://localhost:8080/idr/zarr/v0.1/1.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ome_zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the ilastik projects linked to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(dataset_id):\n",
    "    path = tempfile.mkdtemp()\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    dataset = conn.getObject(\"Dataset\", dataset_id)\n",
    "    # Go through all the annotations on the Dataset\n",
    "    options = []\n",
    "    for ann in dataset.listAnnotations():\n",
    "        if isinstance(ann, omero.gateway.FileAnnotationWrapper):\n",
    "            name = ann.getFile().getName()\n",
    "            # Select the ilatisk project TODO: use namespace\n",
    "            if name.endswith(\".ilp\"):\n",
    "                file_path = os.path.join(path, name)\n",
    "                options.append((name, file_path))\n",
    "                with open(str(file_path), 'wb') as f:\n",
    "                    for chunk in ann.getFileInChunks():\n",
    "                        f.write(chunk)\n",
    "    return widgets.Dropdown(options=options, disabled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function: load an Image as 5D-numpy array: order TZYXC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_numpy_array(image):\n",
    "    pixels = image.getPrimaryPixels()\n",
    "    size_z = image.getSizeZ()\n",
    "    size_c = image.getSizeC()\n",
    "    size_t = image.getSizeT()\n",
    "    size_y = image.getSizeY()\n",
    "    size_x = image.getSizeX()\n",
    "    z, t, c = 0, 0, 0  # first plane of the image\n",
    "\n",
    "    zct_list = []\n",
    "    for t in range(size_t):\n",
    "        for z in range(size_z):  # get the Z-stack\n",
    "            for c in range(size_c):  # all channels\n",
    "                zct_list.append((z, c, t))\n",
    "\n",
    "    values = []\n",
    "    # Load all the planes as YX numpy array\n",
    "    planes = pixels.getPlanes(zct_list)\n",
    "    j = 0\n",
    "    k = 0\n",
    "    tmp_c = []\n",
    "    tmp_z = []\n",
    "    s = \"z:%s t:%s c:%s y:%s x:%s\" % (size_z, size_t, size_c, size_y, size_x)\n",
    "    print(s)\n",
    "    # axis tzyxc\n",
    "    print(\"Downloading image %s\" % image.getName())\n",
    "    for i, p in enumerate(planes):\n",
    "        if k < size_z:\n",
    "            if j < size_c:\n",
    "                tmp_c.append(p)\n",
    "                j = j + 1\n",
    "            if j == size_c:\n",
    "                # use dstack to have c at the end\n",
    "                tmp_z.append(numpy.dstack(tmp_c))\n",
    "                tmp_c = []\n",
    "                j = 0\n",
    "                k = k + 1\n",
    "        if k == size_z:  # done with the stack\n",
    "            values.append(numpy.stack(tmp_z))\n",
    "            tmp_z = []\n",
    "            k = 0\n",
    "\n",
    "    return numpy.stack(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plane_gen():\n",
    "    \"\"\"\n",
    "    Set up a generator of 2D numpy arrays.\n",
    "\n",
    "    The createImage method below expects planes in the order specified here\n",
    "    (for z.. for c.. for t..)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    size_z = data.shape[0]-1\n",
    "    for z in range(data.shape[0]):  # all Z sections data.shape[0]\n",
    "        print('z: %s/%s' % (z, size_z))\n",
    "        for c in range(data.shape[1]):  # all channels\n",
    "            for t in range(data.shape[2]):  # all time-points\n",
    "                yield data[z][c][t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the ilastik project to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_selection = load_model(dataset_id)\n",
    "display(model_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load each image as an 5D-numpy array and analyze.\n",
    "Save the probabilities as an OMERO image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z:236 t:1 c:2 y:275 x:271\n",
      "Downloading image B1_C1.tif\n",
      "Image converted\n",
      "running ilastik headless using /tmp/tmpInvF2D/pixel-class-wednesday.ilp on file B1_C1.tif\n",
      "Saving Probabilities as an Image in OMERO\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Load the model linked to the dataset\n",
    "model_file = model_selection.value\n",
    "\n",
    "images = conn.getObjects('Image', opts={'dataset': dataset_id})\n",
    "\n",
    "# Create a new dataset where to upload the generated images\n",
    "dataset_obj = omero.model.DatasetI()\n",
    "v = \"ilastik_probabilities_from_dataset_%s\" % dataset_id\n",
    "dataset_obj.setName(omero.rtypes.rstring(v))\n",
    "v = \"ilatisk results probabilities from Dataset:%s\" % dataset_id\n",
    "dataset_obj.setDescription(omero.rtypes.rstring(v))\n",
    "dataset_obj = conn.getUpdateService().saveAndReturnObject(dataset_obj)\n",
    "\n",
    "# Prepare ilastik\n",
    "os.environ[\"LAZYFLOW_THREADS\"] = \"2\"\n",
    "os.environ[\"LAZYFLOW_TOTAL_RAM_MB\"] = \"2000\"\n",
    "args = ilastik_main.parse_args([])\n",
    "args.headless = True\n",
    "args.project = model_file\n",
    "shell = ilastik_main.main(args)\n",
    "\n",
    "images = itertools.islice(images, 2)\n",
    "for image in images:\n",
    "    filename, file_extension = os.path.splitext(image.getName())\n",
    "    input_data = load_numpy_array(image)\n",
    "\n",
    "    # run ilastik headless\n",
    "    print('running ilastik using %s and %s' % (model_file, image.getName()))\n",
    "    role_data_dict = OrderedDict(\n",
    "    [\n",
    "        (\n",
    "            \"Raw Data\",\n",
    "            [\n",
    "                PreloadedArrayDatasetInfo(preloaded_array=input_data)\n",
    "            ],\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    predictions = shell.workflow.batchProcessingApplet.run_export(role_data_dict, export_to_array=True)\n",
    "    # Save the probabilities file to the image\n",
    "    print(\"Saving Probabilities as an Image in OMERO\")\n",
    "    name = filename + \"_Probabilities\"\n",
    "    desc = \"ilastik probabilities from Image:%s\" % image.getId()\n",
    "    for data in predictions:\n",
    "        # Re-organise array from tzyxc to zctyx order expected by OMERO\n",
    "        data = data.swapaxes(0, 1).swapaxes(3, 4).swapaxes(2, 3).swapaxes(1, 2)\n",
    "        conn.createImageFromNumpySeq(plane_gen(), name,\n",
    "                                     data.shape[0], data.shape[1],\n",
    "                                     data.shape[2], description=desc,\n",
    "                                     dataset=dataset_obj)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the connection to the OMERO server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### License\n",
    "Copyright (C) 2019-2020 University of Dundee. All Rights Reserved.\n",
    "This program is free software; you can redistribute it and/or modify it\n",
    "under the terms of the GNU General Public License as published by the\n",
    "Free Software Foundation; either version 2 of the License, or\n",
    "(at your option) any later version.\n",
    "This program is distributed in the hope that it will be useful, but\n",
    "WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n",
    "or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for\n",
    "more details. You should have received a copy of the GNU General\n",
    "Public License along with this program; if not, write to the\n",
    "Free Software Foundation,\n",
    "Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:demo]",
   "language": "python",
   "name": "conda-env-demo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
